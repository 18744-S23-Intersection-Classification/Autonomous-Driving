{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Jg4lQ7_WB0wD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680585817528,"user_tz":240,"elapsed":528,"user":{"displayName":"James Li","userId":"03666046569545893260"}},"outputId":"c5c2c1a6-282e-49f1-a797-143d23ed3ac6"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n","gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n","Copyright (C) 2019 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"]}],"source":["# Check nvcc version\n","!nvcc -V\n","# Check GCC version\n","!gcc --version"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_cc4dLdmB_QW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680585949837,"user_tz":240,"elapsed":132319,"user":{"displayName":"James Li","userId":"03666046569545893260"}},"outputId":"2e42ea61-b343-4865-eecf-9826ead2e0f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n","Collecting torch==1.12.0\n","  Downloading https://download.pytorch.org/whl/cu113/torch-1.12.0%2Bcu113-cp39-cp39-linux_x86_64.whl (1837.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m975.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.12.0) (4.5.0)\n","Collecting torchvision\n","  Downloading torchvision-0.15.1-cp39-cp39-manylinux1_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading torchvision-0.14.1-cp39-cp39-manylinux1_x86_64.whl (24.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n","  Downloading torchvision-0.14.0-cp39-cp39-manylinux1_x86_64.whl (24.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.13.1%2Bcu113-cp39-cp39-linux_x86_64.whl (23.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading torchvision-0.13.1-cp39-cp39-manylinux1_x86_64.whl (19.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.13.0%2Bcu113-cp39-cp39-linux_x86_64.whl (23.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.0+cu118\n","    Uninstalling torch-2.0.0+cu118:\n","      Successfully uninstalled torch-2.0.0+cu118\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.15.1+cu118\n","    Uninstalling torchvision-0.15.1+cu118:\n","      Successfully uninstalled torchvision-0.15.1+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.12.0+cu113 which is incompatible.\n","torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.12.0+cu113 which is incompatible.\n","torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.12.0+cu113 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.12.0+cu113 torchvision-0.13.0+cu113\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openmim\n","  Downloading openmim-0.3.7-py2.py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting model-index\n","  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n","Requirement already satisfied: Click in /usr/local/lib/python3.9/dist-packages (from openmim) (8.1.3)\n","Requirement already satisfied: rich in /usr/local/lib/python3.9/dist-packages (from openmim) (13.3.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from openmim) (1.4.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from openmim) (2.27.1)\n","Collecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from openmim) (0.8.10)\n","Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.9/dist-packages (from openmim) (22.0.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from model-index->openmim) (6.0)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.9/dist-packages (from model-index->openmim) (3.4.3)\n","Collecting ordered-set\n","  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->openmim) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->openmim) (2022.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from pandas->openmim) (1.22.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->openmim) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->openmim) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->openmim) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->openmim) (3.4)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich->openmim) (2.2.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich->openmim) (2.14.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->openmim) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown->model-index->openmim) (6.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown->model-index->openmim) (3.15.0)\n","Installing collected packages: ordered-set, colorama, model-index, openmim\n","Successfully installed colorama-0.4.6 model-index-0.1.11 openmim-0.3.7 ordered-set-4.1.0\n","/usr/local/lib/python3.9/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n","  warnings.warn(\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/index.html\n","Collecting mmcv-full==1.6.0\n","  Downloading https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/mmcv_full-1.6.0-cp39-cp39-manylinux1_x86_64.whl (40.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from mmcv-full==1.6.0) (6.0)\n","Collecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from mmcv-full==1.6.0) (8.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mmcv-full==1.6.0) (1.22.4)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.9/dist-packages (from mmcv-full==1.6.0) (4.7.0.72)\n","Collecting yapf\n","  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.2/190.2 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from mmcv-full==1.6.0) (23.0)\n","Installing collected packages: yapf, addict, mmcv-full\n","/usr/local/lib/python3.9/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n","  warnings.warn(\n","Successfully installed addict-2.4.0 mmcv-full-1.6.0 yapf-0.32.0\n"]}],"source":["# Install PyTorch\n","!pip install torch==1.12.0 torchvision --extra-index-url https://download.pytorch.org/whl/cu113\n","# Install MMCV\n","!pip install openmim\n","!mim install mmcv-full==1.6.0"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"6F1lJUQVCBnV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681940195533,"user_tz":240,"elapsed":7679,"user":{"displayName":"James L","userId":"01263273935795395098"}},"outputId":"02840288-1dd2-48a0-e555-ec5ec9c08cb9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mmsegmentation'...\n","remote: Enumerating objects: 14740, done.\u001b[K\n","remote: Counting objects: 100% (327/327), done.\u001b[K\n","remote: Compressing objects: 100% (244/244), done.\u001b[K\n","remote: Total 14740 (delta 105), reused 191 (delta 76), pack-reused 14413\u001b[K\n","Receiving objects: 100% (14740/14740), 20.09 MiB | 18.35 MiB/s, done.\n","Resolving deltas: 100% (10408/10408), done.\n","/content/mmsegmentation\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Obtaining file:///content/mmsegmentation\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mmsegmentation==1.0.0) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mmsegmentation==1.0.0) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from mmsegmentation==1.0.0) (23.1)\n","Requirement already satisfied: prettytable in /usr/local/lib/python3.9/dist-packages (from mmsegmentation==1.0.0) (0.7.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from mmsegmentation==1.0.0) (1.10.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mmsegmentation==1.0.0) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mmsegmentation==1.0.0) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mmsegmentation==1.0.0) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mmsegmentation==1.0.0) (1.4.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mmsegmentation==1.0.0) (1.0.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mmsegmentation==1.0.0) (8.4.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mmsegmentation==1.0.0) (4.39.3)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mmsegmentation==1.0.0) (5.12.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mmsegmentation==1.0.0) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mmsegmentation==1.0.0) (1.16.0)\n","Installing collected packages: mmsegmentation\n","  Running setup.py develop for mmsegmentation\n","Successfully installed mmsegmentation-1.0.0\n"]}],"source":["!rm -rf mmsegmentation\n","!git clone -b main https://github.com/open-mmlab/mmsegmentation.git \n","%cd mmsegmentation\n","!pip install -e ."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2466,"status":"ok","timestamp":1681940202311,"user":{"displayName":"James L","userId":"01263273935795395098"},"user_tz":240},"id":"NZIzuEZjCEZ8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6b8660d0-3969-4e05-8a5c-3874c7708ea3"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.0+cu118 True\n","1.0.0\n"]}],"source":["# Check Pytorch installation\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","\n","# Check MMSegmentation installation\n","import mmseg\n","print(mmseg.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3079,"status":"ok","timestamp":1680585971311,"user":{"displayName":"James Li","userId":"03666046569545893260"},"user_tz":240},"id":"QAkmcgUdCHle","outputId":"6831c59d-4e35-4bff-de2a-15b7c65a15a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-04-04 05:26:07--  https://download.openmmlab.com/mmsegmentation/v0.5/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth\n","Resolving download.openmmlab.com (download.openmmlab.com)... 47.246.48.211, 47.246.48.208, 47.246.48.206, ...\n","Connecting to download.openmmlab.com (download.openmmlab.com)|47.246.48.211|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 196205945 (187M) [application/octet-stream]\n","Saving to: ‘checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth’\n","\n","pspnet_r50-d8_512x1 100%[===================>] 187.12M  67.4MB/s    in 2.8s    \n","\n","2023-04-04 05:26:10 (67.4 MB/s) - ‘checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth’ saved [196205945/196205945]\n","\n"]}],"source":["!mkdir checkpoints\n","!wget https://download.openmmlab.com/mmsegmentation/v0.5/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth -P checkpoints"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1681940289471,"user":{"displayName":"James L","userId":"01263273935795395098"},"user_tz":240},"id":"KwLEnlvbCIHP"},"outputs":[],"source":["from mmseg.apis import inference_model, init_model, show_result_pyplot\n","config_file = 'pspnet_r50-d8_4xb2-40k_cityscapes-512x1024.py'\n","checkpoint_file = 'pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zokiEyBICK_T"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5742,"status":"ok","timestamp":1681940297615,"user":{"displayName":"James L","userId":"01263273935795395098"},"user_tz":240},"id":"JSzVuufJCMVu","outputId":"be144f86-af09-4de8-a167-0e1ee8688554"},"outputs":[{"output_type":"stream","name":"stderr","text":["/content/mmsegmentation/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n","  warnings.warn('``build_loss`` would be deprecated soon, please use '\n","/content/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Loads checkpoint by local backend from path: pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth\n"]}],"source":["# build the model from a config file and a checkpoint file\n","model = init_model(config_file, checkpoint_file, device='cuda:0')"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5937,"status":"ok","timestamp":1681940303541,"user":{"displayName":"James L","userId":"01263273935795395098"},"user_tz":240},"id":"l4K9MXdKCMbD"},"outputs":[],"source":["# test a single image\n","img = 'demo/demo.png'\n","result = inference_model(model, img)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4124,"status":"ok","timestamp":1681940352295,"user":{"displayName":"James L","userId":"01263273935795395098"},"user_tz":240},"id":"_nVP8_3lCMeh","outputId":"3107bbe9-c583-406c-9c82-2bcccf49f473"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[101, 105, 101],\n","        [ 97, 100,  95],\n","        [106, 104,  96],\n","        ...,\n","        [ 98, 103,  92],\n","        [ 98, 103,  92],\n","        [ 96, 102,  95]],\n","\n","       [[133, 140, 126],\n","        [126, 126, 116],\n","        [106, 104,  96],\n","        ...,\n","        [ 96, 100,  90],\n","        [ 98, 103,  92],\n","        [ 98, 103,  92]],\n","\n","       [[111, 130, 112],\n","        [ 99,  99,  80],\n","        [106, 104,  96],\n","        ...,\n","        [ 98, 103,  92],\n","        [ 98, 103,  92],\n","        [ 98, 103,  92]],\n","\n","       ...,\n","\n","       [[ 91,  63,  88],\n","        [ 91,  63,  88],\n","        [ 90,  62,  88],\n","        ...,\n","        [ 96,  69,  96],\n","        [ 97,  70,  96],\n","        [ 98,  71,  98]],\n","\n","       [[ 90,  62,  88],\n","        [ 91,  63,  88],\n","        [ 89,  61,  86],\n","        ...,\n","        [ 88,  58,  84],\n","        [ 88,  58,  84],\n","        [ 85,  58,  85]],\n","\n","       [[ 90,  62,  88],\n","        [ 91,  63,  88],\n","        [ 89,  61,  86],\n","        ...,\n","        [ 88,  60,  87],\n","        [ 86,  59,  87],\n","        [ 88,  58,  84]]], dtype=uint8)"]},"metadata":{},"execution_count":12}],"source":["# show the results\n","show_result_pyplot(model, img, result, out_file='result.jpg')"]},{"cell_type":"code","source":["!mv \"/content/drive/MyDrive/Autonomous Driving/segformer/CAM_FRONT_SEGMENTED/train/\"* \"/content/drive/MyDrive/Autonomous Driving/segformer/CAM_FRONT_SEGMENTED/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ZvXwi-QuJf8","executionInfo":{"status":"ok","timestamp":1680587202527,"user_tz":240,"elapsed":243,"user":{"displayName":"James Li","userId":"03666046569545893260"}},"outputId":"2ef841d9-e642-42ee-e0de-56feb67ce582"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mv: cannot stat '/content/drive/MyDrive/Autonomous Driving/segformer/CAM_FRONT_SEGMENTED/train/*': No such file or directory\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w3RLNjc8CPyr"},"outputs":[],"source":["!pip install nuscenes-devkit &> /dev/null  # Install nuImages."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lk4mFoiu7RII"},"outputs":[],"source":["!tar -xf nuimages-v1.0-all-annotations.tgz -C /data/sets/nuimages"]},{"cell_type":"code","source":["# !rm -rf /content/data\n","!unzip /content/file.zip -d /"],"metadata":{"id":"IIt8FzJ3XW-s"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3045,"status":"ok","timestamp":1679004757223,"user":{"displayName":"James Li","userId":"03666046569545893260"},"user_tz":240},"id":"6WAaDKqOgDgX","outputId":"0f235e1a-5d83-4b74-9405-9e136dcc9a0e"},"outputs":[{"name":"stdout","output_type":"stream","text":["======\n","Loading nuImages tables for version v1.0-train...\n","Done loading in 0.001 seconds (lazy=True).\n","======\n"]}],"source":["%matplotlib inline\n","%reload_ext autoreload\n","%autoreload 2\n","from nuimages import NuImages\n","\n","nuim = NuImages(dataroot='/data/sets/nuimages', version='v1.0-train', verbose=True, lazy=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6j_4TlLsFwsb"},"outputs":[],"source":["data_root = \"/data/sets/nuimages/samples\"\n","img_dir = \"CAM_FRONT\"\n","ann_dir = \"CAM_FRONT_SEGMENTED\"\n","# print(len(nuim.sample_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"elapsed":509,"status":"error","timestamp":1679005338038,"user":{"displayName":"James Li","userId":"03666046569545893260"},"user_tz":240},"id":"tbhafESAlzKy","outputId":"32b5d30e-c1ac-4591-eb93-40fd18bc9907"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3378764d580a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSegmentedColormap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"color_list\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnuim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'nuim' is not defined"]}],"source":["import os.path as osp\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import LinearSegmentedColormap\n","\n","colors = [(1, 0, 0), (0, 1, 0), (0, 0, 1)]\n","cm = LinearSegmentedColormap.from_list(\"color_list\", colors, N=3)\n","\n","for i in range(200000, len(nuim.sample_data)):\n","  if (i % 10000 == 0):\n","    print(i)\n","  data = nuim.sample_data[i]\n","  sample = nuim.get('sample', data['sample_token'])\n","  if data['is_key_frame'] == True and \"/CAM_FRONT/\" in data['filename']:\n","    key_camera_token = sample['key_camera_token']\n","\n","    semantic_mask, _ = nuim.get_segmentation(key_camera_token)\n","    semantic_mask[(semantic_mask != 24) & (semantic_mask != 0)] = 2\n","    semantic_mask[semantic_mask == 24] = 1\n","    fig = plt.figure(frameon=False)\n","    fig.set_size_inches(semantic_mask.shape[1] / 100, semantic_mask.shape[0] / 100)\n","    ax = plt.Axes(fig, [0., 0., 1., 1.])\n","    ax.set_axis_off()\n","    fig.add_axes(ax)\n","    plt.imshow(semantic_mask, cmap=cm, aspect='auto')\n","    target_path = data[\"filename\"].replace(\"/CAM_FRONT/\", \"/CAM_FRONT_SEGMENTED/\", 1)\n","    outpath = osp.join(data_root, target_path)\n","    plt.savefig(outpath)\n","    plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3xbpKkmCEv2b"},"outputs":[],"source":["classes = ('nonroad', 'road', 'obstacles')\n","palette = [[255, 0, 0], [0, 255, 0], [0, 0, 255]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GkjdgFGxIqmd"},"outputs":[],"source":["import os.path as osp\n","\n","# split train/val set randomly\n","split_dir = 'splits'\n","mmcv.mkdir_or_exist(osp.join(data_root, split_dir))\n","filename_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(\n","    osp.join(data_root, ann_dir), suffix='.jpg')]\n","with open(osp.join(data_root, split_dir, 'train.txt'), 'w') as f:\n","  # select first 4/5 as train set\n","  train_length = int(len(filename_list)*4/5)\n","  f.writelines(line + '\\n' for line in filename_list[:train_length])\n","with open(osp.join(data_root, split_dir, 'val.txt'), 'w') as f:\n","  # select last 1/5 as train set\n","  f.writelines(line + '\\n' for line in filename_list[train_length:])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":381,"status":"error","timestamp":1679022972758,"user":{"displayName":"James Li","userId":"03666046569545893260"},"user_tz":240},"id":"xoYeLBA-8EcA","outputId":"f80df75f-61d8-4bc0-a61d-5cdcff829dea"},"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-ebeb9cf3bfcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mDATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNuImagesDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCustomDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mCLASSES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mPALETTE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36m_register\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# use it as a decorator: @x.register_module()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmcv/utils/misc.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;31m# apply converted arguments to the decorated method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36m_register_module\u001b[0;34m(self, module, module_name, force)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mforce\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 raise KeyError(f'{name} is already registered '\n\u001b[0m\u001b[1;32m    273\u001b[0m                                f'in {self.name}')\n\u001b[1;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'NuImagesDataset is already registered in dataset'"]}],"source":["from mmseg.datasets.builder import DATASETS\n","from mmseg.datasets.custom import CustomDataset\n","\n","@DATASETS.register_module()\n","class NuImagesDataset(CustomDataset):\n","  CLASSES = classes\n","  PALETTE = palette\n","  def __init__(self, split, **kwargs):\n","    super().__init__(img_suffix='.jpg', seg_map_suffix='.jpg', \n","                     split=split, **kwargs)\n","    assert osp.exists(self.img_dir) and self.split is not None\n","\n","    "]},{"cell_type":"code","source":["from mmcv import Config\n","cfg = Config.fromfile('configs/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes.py')"],"metadata":{"id":"kNJzfzt1hFxr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":507,"status":"ok","timestamp":1679023014643,"user":{"displayName":"James Li","userId":"03666046569545893260"},"user_tz":240},"id":"ZYb0jQ2pcMlF","outputId":"e1b8cd13-57bb-474b-8731-94a2025c4bf8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Config:\n","norm_cfg = dict(type='BN', requires_grad=True)\n","model = dict(\n","    type='EncoderDecoder',\n","    pretrained='open-mmlab://resnet50_v1c',\n","    backbone=dict(\n","        type='ResNetV1c',\n","        depth=50,\n","        num_stages=4,\n","        out_indices=(0, 1, 2, 3),\n","        dilations=(1, 1, 2, 4),\n","        strides=(1, 2, 1, 1),\n","        norm_cfg=dict(type='BN', requires_grad=True),\n","        norm_eval=False,\n","        style='pytorch',\n","        contract_dilation=True),\n","    decode_head=dict(\n","        type='PSPHead',\n","        in_channels=2048,\n","        in_index=3,\n","        channels=512,\n","        pool_scales=(1, 2, 3, 6),\n","        dropout_ratio=0.1,\n","        num_classes=3,\n","        norm_cfg=dict(type='BN', requires_grad=True),\n","        align_corners=False,\n","        loss_decode=dict(\n","            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n","    auxiliary_head=dict(\n","        type='FCNHead',\n","        in_channels=1024,\n","        in_index=2,\n","        channels=256,\n","        num_convs=1,\n","        concat_input=False,\n","        dropout_ratio=0.1,\n","        num_classes=3,\n","        norm_cfg=dict(type='BN', requires_grad=True),\n","        align_corners=False,\n","        loss_decode=dict(\n","            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n","    train_cfg=dict(),\n","    test_cfg=dict(mode='whole'))\n","dataset_type = 'NuImagesDataset'\n","data_root = '/data/sets/nuimages/samples'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","crop_size = (256, 256)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='Resize', img_scale=(320, 240), ratio_range=(0.5, 2.0)),\n","    dict(type='RandomCrop', crop_size=(256, 256), cat_max_ratio=0.75),\n","    dict(type='RandomFlip', flip_ratio=0.5),\n","    dict(type='PhotoMetricDistortion'),\n","    dict(\n","        type='Normalize',\n","        mean=[123.675, 116.28, 103.53],\n","        std=[58.395, 57.12, 57.375],\n","        to_rgb=True),\n","    dict(type='Pad', size=(256, 256), pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(320, 240),\n","        flip=False,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img'])\n","        ])\n","]\n","data = dict(\n","    samples_per_gpu=8,\n","    workers_per_gpu=8,\n","    train=dict(\n","        type='NuImagesDataset',\n","        data_root='/data/sets/nuimages/samples',\n","        img_dir='CAM_FRONT',\n","        ann_dir='CAM_FRONT_SEGMENTED',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations'),\n","            dict(type='Resize', img_scale=(320, 240), ratio_range=(0.5, 2.0)),\n","            dict(type='RandomCrop', crop_size=(256, 256), cat_max_ratio=0.75),\n","            dict(type='RandomFlip', flip_ratio=0.5),\n","            dict(type='PhotoMetricDistortion'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size=(256, 256), pad_val=0, seg_pad_val=255),\n","            dict(type='DefaultFormatBundle'),\n","            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n","        ],\n","        split='splits/train.txt'),\n","    val=dict(\n","        type='NuImagesDataset',\n","        data_root='/data/sets/nuimages/samples',\n","        img_dir='CAM_FRONT',\n","        ann_dir='CAM_FRONT_SEGMENTED',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(320, 240),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ],\n","        split='splits/val.txt'),\n","    test=dict(\n","        type='NuImagesDataset',\n","        data_root='/data/sets/nuimages/samples',\n","        img_dir='CAM_FRONT',\n","        ann_dir='CAM_FRONT_SEGMENTED',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(320, 240),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ],\n","        split='splits/val.txt'))\n","log_config = dict(\n","    interval=10, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = 'checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n","resume_from = None\n","workflow = [('train', 1)]\n","cudnn_benchmark = True\n","optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n","optimizer_config = dict()\n","lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)\n","runner = dict(type='IterBasedRunner', max_iters=200)\n","checkpoint_config = dict(by_epoch=False, interval=200)\n","evaluation = dict(interval=200, metric='mIoU', pre_eval=True)\n","work_dir = './work_dirs/tutorial'\n","seed = 0\n","gpu_ids = range(0, 1)\n","device = 'cuda'\n","\n"]}],"source":["from mmseg.apis import set_random_seed\n","from mmseg.utils import get_device\n","\n","# Since we use only one GPU, BN is used instead of SyncBN\n","cfg.norm_cfg = dict(type='BN', requires_grad=True)\n","cfg.model.backbone.norm_cfg = cfg.norm_cfg\n","cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n","cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n","# modify num classes of the model in decode/auxiliary head\n","cfg.model.decode_head.num_classes = 3\n","cfg.model.auxiliary_head.num_classes = 3\n","\n","# Modify dataset type and path\n","cfg.dataset_type = 'NuImagesDataset'\n","cfg.data_root = data_root\n","\n","cfg.data.samples_per_gpu = 8\n","cfg.data.workers_per_gpu = 8\n","\n","cfg.img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","cfg.crop_size = (256, 256)\n","cfg.train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='Resize', img_scale=(320, 240), ratio_range=(0.5, 2.0)),\n","    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n","    dict(type='RandomFlip', flip_ratio=0.5),\n","    dict(type='PhotoMetricDistortion'),\n","    dict(type='Normalize', **cfg.img_norm_cfg),\n","    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n","]\n","\n","cfg.test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(320, 240),\n","        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n","        flip=False,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(type='Normalize', **cfg.img_norm_cfg),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img']),\n","        ])\n","]\n","\n","\n","cfg.data.train.type = cfg.dataset_type\n","cfg.data.train.data_root = cfg.data_root\n","cfg.data.train.img_dir = img_dir\n","cfg.data.train.ann_dir = ann_dir\n","cfg.data.train.pipeline = cfg.train_pipeline\n","cfg.data.train.split = 'splits/train.txt'\n","\n","cfg.data.val.type = cfg.dataset_type\n","cfg.data.val.data_root = cfg.data_root\n","cfg.data.val.img_dir = img_dir\n","cfg.data.val.ann_dir = ann_dir\n","cfg.data.val.pipeline = cfg.test_pipeline\n","cfg.data.val.split = 'splits/val.txt'\n","\n","cfg.data.test.type = cfg.dataset_type\n","cfg.data.test.data_root = cfg.data_root\n","cfg.data.test.img_dir = img_dir\n","cfg.data.test.ann_dir = ann_dir\n","cfg.data.test.pipeline = cfg.test_pipeline\n","cfg.data.test.split = 'splits/val.txt'\n","\n","# We can still use the pre-trained Mask RCNN model though we do not need to\n","# use the mask branch\n","cfg.load_from = 'checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n","\n","# Set up working dir to save files and logs.\n","cfg.work_dir = './work_dirs/tutorial'\n","\n","cfg.runner.max_iters = 200\n","cfg.log_config.interval = 10\n","cfg.evaluation.interval = 200\n","cfg.checkpoint_config.interval = 200\n","\n","# Set seed to facitate reproducing the result\n","cfg.seed = 0\n","set_random_seed(0, deterministic=False)\n","cfg.gpu_ids = range(1)\n","cfg.device = get_device()\n","\n","# Let's have a look at the final config used for training\n","print(f'Config:\\n{cfg.pretty_text}')"]},{"cell_type":"code","source":["from mmseg.datasets import build_dataset\n","from mmseg.models import build_segmentor\n","from mmseg.apis import train_segmentor\n","\n","\n","# Build the dataset\n","datasets = [build_dataset(cfg.data.train)]\n","\n","# Build the detector\n","model = build_segmentor(cfg.model)\n","# Add an attribute for visualization convenience\n","model.CLASSES = datasets[0].CLASSES\n","\n","# Create work_dir\n","mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n","train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n","                meta=dict())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"akkWA51AhSnR","executionInfo":{"status":"error","timestamp":1679023027366,"user_tz":240,"elapsed":5119,"user":{"displayName":"James Li","userId":"03666046569545893260"}},"outputId":"e848042a-0044-486b-811e-50ab3a4d61b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2023-03-17 03:17:01,018 - mmseg - INFO - Loaded 10549 images\n","2023-03-17 03:17:01,658 - mmseg - INFO - Loaded 2638 images\n","2023-03-17 03:17:01,660 - mmseg - INFO - load checkpoint from local path: checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth\n","2023-03-17 03:17:01,957 - mmseg - WARNING - The model and loaded state dict do not match exactly\n","\n","size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([19, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([3, 512, 1, 1]).\n","size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([19]) from checkpoint, the shape in current model is torch.Size([3]).\n","size mismatch for auxiliary_head.conv_seg.weight: copying a param with shape torch.Size([19, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([3, 256, 1, 1]).\n","size mismatch for auxiliary_head.conv_seg.bias: copying a param with shape torch.Size([19]) from checkpoint, the shape in current model is torch.Size([3]).\n","2023-03-17 03:17:01,967 - mmseg - INFO - Start running, host: root@ef7b72c9f476, work_dir: /content/mmsegmentation/work_dirs/tutorial\n","2023-03-17 03:17:01,968 - mmseg - INFO - Hooks will be executed in the following order:\n","before_run:\n","(VERY_HIGH   ) PolyLrUpdaterHook                  \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_epoch:\n","(VERY_HIGH   ) PolyLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_iter:\n","(VERY_HIGH   ) PolyLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n"," -------------------- \n","after_train_iter:\n","(ABOVE_NORMAL) OptimizerHook                      \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_train_epoch:\n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_epoch:\n","(LOW         ) IterTimerHook                      \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_epoch:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_run:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","2023-03-17 03:17:01,973 - mmseg - INFO - workflow: [('train', 1)], max: 200 iters\n","2023-03-17 03:17:01,975 - mmseg - INFO - Checkpoints will be saved to /content/mmsegmentation/work_dirs/tutorial by HardDiskBackend.\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-66-1378e34063c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Create work_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir_or_exist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwork_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n\u001b[0m\u001b[1;32m     17\u001b[0m                 meta=dict())\n","\u001b[0;32m/content/mmsegmentation/mmseg/apis/train.py\u001b[0m in \u001b[0;36mtrain_segmentor\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmcv/runner/iter_based_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_loaders, workflow, max_iters, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_iters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                     \u001b[0miter_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait for some hooks like loggers to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmcv/runner/iter_based_runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_train_iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.train_step() must return a dict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmcv/parallel/data_parallel.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/mmsegmentation/mmseg/models/segmentors/base.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data_batch, optimizer, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0maveraging\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmcv/runner/fp16_utils.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m                                 f'method of those classes {supported_types}')\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fp16_enabled'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16_enabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mold_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;31m# get the arg spec of the decorated method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/mmsegmentation/mmseg/models/segmentors/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img, img_metas, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/mmsegmentation/mmseg/models/segmentors/encoder_decoder.py\u001b[0m in \u001b[0;36mforward_train\u001b[0;34m(self, img, img_metas, gt_semantic_seg)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         loss_decode = self._decode_head_forward_train(x, img_metas,\n\u001b[0m\u001b[1;32m    145\u001b[0m                                                       gt_semantic_seg)\n\u001b[1;32m    146\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_decode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/mmsegmentation/mmseg/models/segmentors/encoder_decoder.py\u001b[0m in \u001b[0;36m_decode_head_forward_train\u001b[0;34m(self, x, img_metas, gt_semantic_seg)\u001b[0m\n\u001b[1;32m     85\u001b[0m         training.\"\"\"\n\u001b[1;32m     86\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         loss_decode = self.decode_head.forward_train(x, img_metas,\n\u001b[0m\u001b[1;32m     88\u001b[0m                                                      \u001b[0mgt_semantic_seg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                                                      self.train_cfg)\n","\u001b[0;32m/content/mmsegmentation/mmseg/models/decode_heads/decode_head.py\u001b[0m in \u001b[0;36mforward_train\u001b[0;34m(self, inputs, img_metas, gt_semantic_seg, train_cfg)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \"\"\"\n\u001b[1;32m    242\u001b[0m         \u001b[0mseg_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_semantic_seg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmcv/runner/fp16_utils.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m                                 'method of nn.Module')\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fp16_enabled'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16_enabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mold_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0;31m# get the arg spec of the decorated method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0margs_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/mmsegmentation/mmseg/models/decode_heads/decode_head.py\u001b[0m in \u001b[0;36mlosses\u001b[0;34m(self, seg_logit, seg_label)\u001b[0m\n\u001b[1;32m    279\u001b[0m                 input=seg_label, size=target_size, mode='nearest')\n\u001b[1;32m    280\u001b[0m             \u001b[0mseg_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         seg_logit = resize(\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseg_logit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseg_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/mmsegmentation/mmseg/ops/wrappers.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(input, size, scale_factor, mode, align_corners, warning)\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[0;34mf'input size {(input_h, input_w)} is `x+1` and '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                         f'out size {(output_h, output_w)} is `nx+1`')\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3852\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3853\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3854\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   3855\u001b[0m                     \u001b[0;34m\"Input and output must have the same number of spatial dimensions, but got \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3856\u001b[0m                     \u001b[0;34mf\"input with with spatial dimensions of {list(input.shape[2:])} and output size of {size}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input and output must have the same number of spatial dimensions, but got input with with spatial dimensions of [32, 32] and output size of torch.Size([256, 256, 3]). Please provide input tensor in (N, C, d1, d2, ...,dK) format and output size in (o1, o2, ...,oK) format."]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7C84Ykb5fLs4","colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"status":"error","timestamp":1679022534190,"user_tz":240,"elapsed":14,"user":{"displayName":"James Li","userId":"03666046569545893260"}},"outputId":"8120081b-670b-464f-9cd3-e7029c0d4de3"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-f2d4611626e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSegmentedColormap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"color_list\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnuim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnuim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnuim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'nuim' is not defined"]}],"source":["import os.path as osp\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import LinearSegmentedColormap\n","\n","colors = [(1, 0, 0), (0, 1, 0), (0, 0, 1)]\n","cm = LinearSegmentedColormap.from_list(\"color_list\", colors, N=3)\n","\n","for i in range(len(nuim.sample_data)):\n","  data = nuim.sample_data[i]\n","  sample = nuim.get('sample', data['sample_token'])\n","  if data['is_key_frame'] == True and \"/CAM_FRONT/\" in data['filename']:\n","    key_camera_token = sample['key_camera_token']\n","\n","    semantic_mask, _ = nuim.get_segmentation(key_camera_token)\n","    semantic_mask[(semantic_mask != 24) & (semantic_mask != 0)] = 2\n","    semantic_mask[semantic_mask == 24] = 1\n","    fig = plt.figure(figsize=figsize, frameon=False)\n","    fig.set_size_inches(semantic_mask.shape[1] / 100, semantic_mask.shape[0] / 100)\n","    ax = plt.Axes(fig, [0., 0., 1., 1.])\n","    ax.set_axis_off()\n","    fig.add_axes(ax)\n","    plt.imshow(semantic_mask, cmap=cm, aspect='auto')\n","    plt.savefig(\"/content/test.png\")\n","    plt.close()\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":376,"status":"ok","timestamp":1679001830073,"user":{"displayName":"James Li","userId":"03666046569545893260"},"user_tz":240},"id":"aKpFwWa-LZ2h","outputId":"9d28b9ac-1fd6-4833-fd60-bd52a987f882"},"outputs":[{"name":"stdout","output_type":"stream","text":["[(0, 0, 255, 255), (0, 255, 0, 255), (255, 0, 0, 255)]\n"]}],"source":["from PIL import Image\n","im = Image.open('/content/test.png', 'r')\n","width, height = im.size\n","pixel_values = list(im.getdata())\n","# print(pixel_values)\n","pixel_values = [*set(pixel_values)]\n","print(pixel_values)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ddKukUaS7XT"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}