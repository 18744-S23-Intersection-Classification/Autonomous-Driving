{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"uQLgYg6E6X43","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682707773798,"user_tz":240,"elapsed":661,"user":{"displayName":"James L","userId":"01263273935795395098"}},"outputId":"c3dbc03b-8436-43b3-d1cc-4bc24f05a9c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n","gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n","Copyright (C) 2019 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"]}],"source":["# Check nvcc version\n","!nvcc -V\n","# Check GCC version\n","!gcc --version"]},{"cell_type":"code","source":["!pip install openmim\n","!pip install scikit-video\n","!mim install mmengine\n","!mim install \"mmcv>=2.0.0\""],"metadata":{"id":"NcNbxqYN6in8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682707818788,"user_tz":240,"elapsed":44995,"user":{"displayName":"James L","userId":"01263273935795395098"}},"outputId":"e99274f6-3776-4157-cf07-b4c00bd30198"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openmim\n","  Downloading openmim-0.3.7-py2.py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.27.1)\n","Collecting model-index\n","  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n","Requirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.3)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.3.4)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.8.10)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (1.5.3)\n","Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (23.0.1)\n","Collecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting ordered-set\n","  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.4.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.22.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2022.7.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.4)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.14.0)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.2.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->openmim) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n","Installing collected packages: ordered-set, colorama, model-index, openmim\n","Successfully installed colorama-0.4.6 model-index-0.1.11 openmim-0.3.7 ordered-set-4.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scikit-video\n","  Downloading scikit_video-1.1.11-py2.py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.10.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from scikit-video) (8.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.22.4)\n","Installing collected packages: scikit-video\n","Successfully installed scikit-video-1.1.11\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n","Collecting mmengine\n","  Downloading mmengine-0.7.3-py3-none-any.whl (372 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.1/372.1 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmengine) (6.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine) (3.7.1)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine) (4.7.0.72)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmengine) (1.22.4)\n","Collecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine) (13.3.4)\n","Collecting yapf\n","  Downloading yapf-0.33.0-py2.py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.9/200.9 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine) (2.3.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (4.39.3)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.4.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.0.7)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (2.8.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (8.4.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (0.11.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (2.14.0)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (2.2.0)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (2.0.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->mmengine) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\n","Installing collected packages: addict, yapf, mmengine\n","Successfully installed addict-2.4.0 mmengine-0.7.3 yapf-0.33.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n","Collecting mmcv>=2.0.0\n","  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/mmcv-2.0.0-cp310-cp310-manylinux1_x86_64.whl (74.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (2.4.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (6.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (8.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (23.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (1.22.4)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (4.7.0.72)\n","Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (0.33.0)\n","Requirement already satisfied: mmengine>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0) (0.7.3)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.2.0->mmcv>=2.0.0) (13.3.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.2.0->mmcv>=2.0.0) (3.7.1)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.2.0->mmcv>=2.0.0) (2.3.0)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0) (2.0.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv>=2.0.0) (2.8.2)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv>=2.0.0) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv>=2.0.0) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv>=2.0.0) (0.11.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv>=2.0.0) (1.0.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv>=2.0.0) (3.0.9)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.2.0->mmcv>=2.0.0) (2.14.0)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.2.0->mmcv>=2.0.0) (2.2.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->mmengine>=0.2.0->mmcv>=2.0.0) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.2.0->mmcv>=2.0.0) (1.16.0)\n","Installing collected packages: mmcv\n","Successfully installed mmcv-2.0.0\n"]}]},{"cell_type":"code","source":["!rm -rf mmsegmentation\n","!git clone -b main https://github.com/open-mmlab/mmsegmentation.git \n","%cd mmsegmentation\n","!pip install -e ."],"metadata":{"id":"yn3H0gIg6kue","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682707827104,"user_tz":240,"elapsed":8337,"user":{"displayName":"James L","userId":"01263273935795395098"}},"outputId":"ff975613-a125-46fa-a0f2-c18eecd7bbd0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mmsegmentation'...\n","remote: Enumerating objects: 14797, done.\u001b[K\n","remote: Counting objects: 100% (384/384), done.\u001b[K\n","remote: Compressing objects: 100% (301/301), done.\u001b[K\n","remote: Total 14797 (delta 134), reused 211 (delta 76), pack-reused 14413\u001b[K\n","Receiving objects: 100% (14797/14797), 20.14 MiB | 23.76 MiB/s, done.\n","Resolving deltas: 100% (10448/10448), done.\n","/content/mmsegmentation\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Obtaining file:///content/mmsegmentation\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==1.0.0) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==1.0.0) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==1.0.0) (23.1)\n","Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==1.0.0) (0.7.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==1.0.0) (1.10.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.0.0) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.0.0) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.0.0) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.0.0) (4.39.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.0.0) (2.8.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.0.0) (8.4.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.0.0) (1.0.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmsegmentation==1.0.0) (1.16.0)\n","Installing collected packages: mmsegmentation\n","  Running setup.py develop for mmsegmentation\n","Successfully installed mmsegmentation-1.0.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"eQdYKbnb7jgv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682707883475,"user_tz":240,"elapsed":56398,"user":{"displayName":"James L","userId":"01263273935795395098"}},"outputId":"9773002a-8b8b-4f48-ace8-af091d055427"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Check Pytorch installation\n","import torch, torchvision\n","\n","# Check MMSegmentation installation\n","import mmseg\n","\n","from __future__ import print_function, division\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","\n","cudnn.benchmark = True\n","plt.ion()   # interactive mode"],"metadata":{"id":"xMmI5S4i6lXe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682707887340,"user_tz":240,"elapsed":3887,"user":{"displayName":"James L","userId":"01263273935795395098"}},"outputId":"4fe00eb1-669c-4a36-9b2f-7a74c166a5fe"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<contextlib.ExitStack at 0x7fab72d3beb0>"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["!mim download mmsegmentation --config segformer_mit-b0_8xb1-160k_cityscapes-1024x1024 --dest ."],"metadata":{"id":"CiLq8XKy6rTj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682707894416,"user_tz":240,"elapsed":7090,"user":{"displayName":"James L","userId":"01263273935795395098"}},"outputId":"5db317a0-4da4-4b0d-832e-6b00e4109d83"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["processing segformer_mit-b0_8xb1-160k_cityscapes-1024x1024...\n","\u001b[2Kdownloading \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MiB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[32mSuccessfully downloaded segformer_mit-b0_8x1_1024x1024_160k_cityscapes_20211208_101857-e7f88502.pth to /content/mmsegmentation\u001b[0m\n","\u001b[32mSuccessfully dumped segformer_mit-b0_8xb1-160k_cityscapes-1024x1024.py to /content/mmsegmentation\u001b[0m\n"]}]},{"cell_type":"code","source":["from mmseg.apis import inference_model, init_model, show_result_pyplot\n","config_file = '/content/mmsegmentation/segformer_mit-b0_8xb1-160k_cityscapes-1024x1024.py'\n","checkpoint_file = '/content/mmsegmentation/segformer_mit-b0_8x1_1024x1024_160k_cityscapes_20211208_101857-e7f88502.pth'"],"metadata":{"id":"ncwxgmPH6tcv","executionInfo":{"status":"ok","timestamp":1682707895739,"user_tz":240,"elapsed":1358,"user":{"displayName":"James L","userId":"01263273935795395098"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# build the model from a config file and a checkpoint file\n","model = init_model(config_file, checkpoint_file, device='cuda:0')"],"metadata":{"id":"8h-E3XYe6wI4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682707903983,"user_tz":240,"elapsed":8247,"user":{"displayName":"James L","userId":"01263273935795395098"}},"outputId":"3801d2df-107a-4f32-ae50-4b5a3ba6706c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/mmsegmentation/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n","  warnings.warn('``build_loss`` would be deprecated soon, please use '\n","/content/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Loads checkpoint by local backend from path: /content/mmsegmentation/segformer_mit-b0_8x1_1024x1024_160k_cityscapes_20211208_101857-e7f88502.pth\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","model_pt = torch.load(\"/content/drive/MyDrive/Autonomous Driving/front_classifier/weights_segformer.pth\")\n","model_pt.to(device)\n","model_pt.eval()"],"metadata":{"id":"mCUj2773GvAX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682707905620,"user_tz":240,"elapsed":1644,"user":{"displayName":"James L","userId":"01263273935795395098"}},"outputId":"e3df9488-c4c1-428d-b892-1c6e767d2cd9"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MobileNetV2(\n","  (features): Sequential(\n","    (0): Conv2dNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","    (1): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (16): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (17): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (18): Conv2dNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=False)\n","    (1): Linear(in_features=1280, out_features=1000, bias=True)\n","  )\n","  (fc): Linear(in_features=1280, out_features=5, bias=True)\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["def getLines(img):\n","\n","    # Define the color ranges for each color of interest for creating masks.\n","    COLOR1_RANGE = [(30, 0, 0), (255, 50, 50)]  # Blue in BGR, [(low), (high)].\n","    COLOR2_RANGE = [(0, 30, 0), (50, 255, 50)] \n","\n","    # Create masks:\n","    color1_mask = cv2.inRange(img, COLOR1_RANGE[0], COLOR1_RANGE[1])\n","    color2_mask = cv2.inRange(img, COLOR2_RANGE[0], COLOR2_RANGE[1])\n","\n","    # Adjust according to your adjacency requirement.\n","    kernel = np.ones((3, 3), dtype=np.uint8)\n","\n","    # Dilating masks to expand boundary.\n","    color1_mask = cv2.dilate(color1_mask, kernel, iterations=1)\n","    color2_mask = cv2.dilate(color2_mask, kernel, iterations=1)\n","\n","    # Required points now will have both color's mask val as 255.\n","    common = cv2.bitwise_and(color1_mask, color2_mask)\n","    return common"],"metadata":{"id":"C3my8ThkfSV4","executionInfo":{"status":"ok","timestamp":1682707905623,"user_tz":240,"elapsed":19,"user":{"displayName":"James L","userId":"01263273935795395098"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# original pipeline\n","\n","from PIL import Image\n","import cv2\n","import matplotlib.pyplot as plt\n","import time\n","import glob\n","\n","predictions = [0, 0, 0, 0, 0]\n","for filename in glob.glob(\"/content/drive/MyDrive/mobilenet/k360/test/3/6_0000001610.png\"):\n","  t0 = time.time()\n","  im = Image.open(filename)\n","  im.save(\"temp.png\")\n","  im = np.array(im)\n","  result = inference_model(model, im)\n","  img = show_result_pyplot(model, im, result, show=False, opacity=1.0)\n","  red, green, blue = img.T # Temporarily unpack the bands for readability\n","\n","  car_area = (red == 0) & (green == 0) & (blue == 142)\n","  truck_area = (red == 0) & (green == 0) & (blue == 70)\n","  bus_area = (red == 0) & (green == 60) & (blue == 100)\n","  caravan_area = (red == 0) & (green == 0) & (blue == 90)\n","  trailer_area = (red == 0) & (green == 0) & (blue == 110)\n","  train_area = (red == 0) & (green == 80) & (blue == 100)\n","  motorcycle_area = (red == 0) & (green == 0) & (blue == 230)\n","  bicycle_area = (red == 119) & (green == 11) & (blue == 32)\n","  road_area = (red == 128) & (green == 64) & (blue == 128)\n","  pedestrian_area = (red == 220) & (green == 20) & (blue == 60)\n","  img[:,:,:3] = (0, 255, 0)\n","  img[:,:,:3][car_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][truck_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][bus_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][caravan_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][trailer_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][train_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][motorcycle_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][bicycle_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][pedestrian_area.T] = (0, 0, 255)\n","  img[:,:,:3][road_area.T] = (255, 0, 0) # Transpose back needed\n","  img = Image.fromarray(img)\n","  img.save(\"result.jpg\")\n","\n","  t1 = time.time()\n","\n","  # 0=straight, 1=left T, 2=right T, 3=left/right T, 4=cross\n","  class_names = ['fourway', 'straight', 'threeway_left', 'threeway_right', 'threeway_t']\n","  data_transforms = transforms.Compose([\n","          transforms.Resize((224, 224)),\n","          transforms.ToTensor(),\n","          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","      ])\n","\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","  img = data_transforms(img).unsqueeze(0)\n","  img = img.to(device)\n","\n","  output = model_pt(img)\n","  pred = output.cpu().data.numpy().argmax()\n","  t2 = time.time()\n","\n","  # img = cv2.imread(img_path) # reads image\n","  predictions[pred] += 1\n","  print(class_names[pred], t1 - t0, t2 - t1, t2 - t0)\n","  break\n","\n","print(predictions)\n"],"metadata":{"id":"jhHljHaN63Ao","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682708082056,"user_tz":240,"elapsed":3910,"user":{"displayName":"James L","userId":"01263273935795395098"}},"outputId":"d8ea72c3-2565-4b77-9714-acf13e95ed64"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["04/28 18:54:38 - mmengine - WARNING - `Visualizer` backend is not initialized because save_dir is None.\n","threeway_t 3.0952839851379395 0.17357087135314941 3.268854856491089\n","[0, 0, 0, 0, 1]\n"]}]},{"cell_type":"code","source":["from PIL import Image\n","import cv2\n","import skvideo.io\n","import matplotlib.pyplot as plt\n","import time\n","import glob\n","import matplotlib.pyplot as plt\n","import io\n","import natsort\n","\n","predictions = [0, 0, 0, 0, 0]\n","# video_frames = skvideo.io.vread(\"/content/drive/MyDrive/bev/sample.gif\")\n","# video_frames = skvideo.io.vread(\"/content/videoplayback.mp4\", num_frames = 20000)\n","\n","frames = []\n","\n","filenames = glob.glob(\"/content/drive/MyDrive/mobilenet/k360/test/*/*.png\")\n","filenames = natsort.natsorted(filenames)\n","print(filenames)\n","\n","for filename in filenames:\n","  f, axarr = plt.subplots(3, figsize=(10,10))\n","\n","  # segmentation\n","  t0 = time.time()\n","  im = Image.open(filename)\n","  im = np.array(im)\n","  axarr[0].imshow(im)\n","  result = inference_model(model, im)\n","  img = show_result_pyplot(model, im, result, show=False, opacity=1.0)\n","  red, green, blue = img.T # Temporarily unpack the bands for readability\n","\n","  car_area = (red == 0) & (green == 0) & (blue == 142)\n","  truck_area = (red == 0) & (green == 0) & (blue == 70)\n","  bus_area = (red == 0) & (green == 60) & (blue == 100)\n","  caravan_area = (red == 0) & (green == 0) & (blue == 90)\n","  trailer_area = (red == 0) & (green == 0) & (blue == 110)\n","  train_area = (red == 0) & (green == 80) & (blue == 100)\n","  motorcycle_area = (red == 0) & (green == 0) & (blue == 230)\n","  bicycle_area = (red == 119) & (green == 11) & (blue == 32)\n","  road_area = (red == 128) & (green == 64) & (blue == 128)\n","  pedestrian_area = (red == 220) & (green == 20) & (blue == 60)\n","  img[:,:,:3] = (0, 255, 0)\n","  img[:,:,:3][car_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][truck_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][bus_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][caravan_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][trailer_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][train_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][motorcycle_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][bicycle_area.T] = (0, 0, 255) # Transpose back needed\n","  img[:,:,:3][pedestrian_area.T] = (0, 0, 255)\n","  img[:,:,:3][road_area.T] = (255, 0, 0) # Transpose back needed\n","  lines = getLines(img)\n","  img = Image.fromarray(img)\n","  axarr[1].imshow(img)\n","  \n","  axarr[2].imshow(lines)\n","  plt.axis('off')\n","\n","  t1 = time.time()\n","\n","  # classification\n","  # 0=straight, 1=left T, 2=right T, 3=left/right T, 4=cross\n","  class_names = ['fourway', 'straight', 'threeway_left', 'threeway_right', 'threeway_t']\n","  data_transforms = transforms.Compose([\n","          transforms.Resize((224, 224)),\n","          transforms.ToTensor(),\n","          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","      ])\n","\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","  img = data_transforms(img).unsqueeze(0)\n","  img = img.to(device)\n","\n","  output = model_pt(img)\n","  pred = output.cpu().data.numpy().argmax()\n","  t2 = time.time()\n","\n","  # display predicted intersection types\n","  axarr[0].text(20, 40, class_names[pred], color='red', fontsize='large', fontweight='bold')\n","  img_buf = io.BytesIO()\n","  plt.close()\n","  f.savefig(img_buf, format='png')\n","\n","  plot_im = Image.open(img_buf)\n","  frames.append(plot_im)\n","\n","  predictions[pred] += 1\n","  # print(class_names[pred], t1 - t0, t2 - t1, t2 - t0)\n","\n","frame_one = frames[0]\n","frame_one.save(\"/content/test.gif\", format=\"GIF\", append_images=frames, save_all=True, duration=500, loop=0)\n","\n","print(predictions)  # print all predictions made on the video frames\n"],"metadata":{"id":"HIMEA63ZMmYf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# install latest labelbox version (3.0 or above)\n","!pip3 install labelbox[data]\n","\n","import labelbox\n","# Enter your Labelbox API key here\n","LB_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjbGd5NG44cWMwOW53MDd6dTY4YjVlNzdzIiwib3JnYW5pemF0aW9uSWQiOiJjbGd5NG44cHQwOW52MDd6dTRvbHI3M2Q4IiwiYXBpS2V5SWQiOiJjbGgwMzFlaTgwMDd5MDcwdmh6cDIwem52Iiwic2VjcmV0IjoiZTM1NzdiOWZiMTM5ZDMwMWZkMjRiYzVjN2NhNjJiZjkiLCJpYXQiOjE2ODI2NTc4NTAsImV4cCI6MjMxMzgwOTg1MH0.Dzqjj5NQOhQzFjkmYFEMhdsTDh8-dI2Brhs6LsJ9nuk\"\n","# Create Labelbox client\n","lb = labelbox.Client(api_key=LB_API_KEY)\n","# Get project by ID\n","project = lb.get_project('clgy83nec00d107xphkmb3x3i')\n","# Export image and text data as an annotation generator:\n","# labels = project.label_generator()\n","# # Export labels created in the selected date range as a json file:\n","labels = project.export_labels(download = True, start=\"2023-04-22\", end=\"2023-04-28\")"],"metadata":{"id":"jn6ele24G5Ve"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://rr5---sn-8xgp1vo-2pue.googlevideo.com/videoplayback?expire=1682679647&ei=_1JLZKzLMJX1Wszak_AG&ip=45.133.172.205&id=o-ADengbi1QPykjwhRL1w67F9I9XQhAcbztWf9v_87VjAD&itag=18&source=youtube&requiressl=yes&spc=qEK7B7bldoB3-xbm4OfD33VSoK1ncVLU5ZJQhtwLPQ&vprv=1&mime=video%2Fmp4&ns=bqXJ-be_748CeJu0C_Q6lP0N&cnr=14&ratebypass=yes&dur=1441.030&lmt=1664073137235145&fexp=24007246&c=WEB&txp=5438434&n=QHh4YIT9nm80iw&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cspc%2Cvprv%2Cmime%2Cns%2Ccnr%2Cratebypass%2Cdur%2Clmt&sig=AOq0QJ8wRQIgeQ6xdcDWA5BUe1zTLLYHdSzIdDVLRD-bd63l3E8Q7KcCIQDe4CUPqD7gtY9e2fNAykReavb_z3uIb6qJ3pz7aeQKIg%3D%3D&redirect_counter=1&rm=sn-4g5ez77z&req_id=5e8adb6bba2da3ee&cms_redirect=yes&cmsv=e&ipbypass=yes&mh=kl&mip=2600:4041:4a2:b800:9487:1e1b:2066:cb04&mm=31&mn=sn-8xgp1vo-2pue&ms=au&mt=1682657829&mv=m&mvi=5&pl=38&lsparams=ipbypass,mh,mip,mm,mn,ms,mv,mvi,pl&lsig=AG3C_xAwRAIgL6aOZJ169nQyUUmk5ZG4kBlLN2HDyeZ3ZjnGYRZUVZsCIC5JvBFdOhTP8c_UDmvp1zXp-908xX6J_Ow8-Km6iUaP"],"metadata":{"id":"MGes7fCoOUop"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"paaJEdnaPJkI"},"execution_count":null,"outputs":[]}]}